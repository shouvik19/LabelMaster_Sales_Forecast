# salesimport numpy as npimport pandas as pdimport copyimport datetimeimport matplotlib.pyplot as pltimport seaborn as snsdef read_excel_file(file_path,file_list):    print('Reading sales files. This may take some time.')    for i in range(len(file_list)):        if i==0:            file_1=pd.read_excel(open(str(file_path)+str(file_names[0]), 'rb'),sheet_name='Sheet1')            file_1.iloc[1,:][0]            file_1.columns=[file_1.iloc[1,:][0],file_1.iloc[1,:][1],file_1.iloc[1,:][2],file_1.iloc[1,:][3]]            file_1.drop([0,1],axis=0,inplace=True)            if (file_1.columns[0]!='Department Dim') | (file_1.columns[1]!='Product Group Code') | (file_1.columns[2]!='Posting Date') | (file_1.columns[3]!='Sum of Sales'):                print('Column names not matching for {cc}. Expected Department Dim, Product Group Code, Posting Date, Sum of Sales respectively in 3rd row'                      .format(cc=str(file_names[0])))                        #file_1=pd.read_excel(open(str(file_path)+str(file_list[i]), 'rb'),sheet_name='Sheet1',header=None)            # put a checkpoint to check the column names are correct            #file_1.drop([0,1,2],axis=0,inplace=True)            #file_1.rename(columns={0: "Department_Dim", 1: "Product_Group_Code", 2: "Posting_Date", 3: "Sum_of_Sales"}, inplace=True)        else:            file=pd.read_excel(open(str(file_path)+str(file_names[i]), 'rb'),sheet_name='Sheet1')            file.iloc[1,:][0]            file.columns=[file.iloc[1,:][0],file.iloc[1,:][1],file.iloc[1,:][2],file.iloc[1,:][3]]            file.drop([0,1],axis=0,inplace=True)            if (file.columns[0]!='Department Dim') | (file.columns[1]!='Product Group Code') | (file.columns[2]!='Posting Date') | (file.columns[3]!='Sum of Sales'):                print('Column names not matching for {cc}. Expected Department Dim, Product Group Code, Posting Date, Sum of Sales respectively in 3rd row'                      .format(cc=str(file_names[i])))                        #file=pd.read_excel(open(str(file_path)+str(file_list[i]), 'rb'),sheet_name='Sheet1',header=None)            #file.drop([0,1,2],axis=0,inplace=True)                        file_1=pd.concat([file_1,file],ignore_index=True)    file_1.rename(columns={'Department Dim': "Department_Dim", 'Product Group Code': "Product_Group_Code", 'Posting Date': "Posting_Date", 'Sum of Sales': "Sum_of_Sales"}, inplace=True)    print('Read successfully')    return file_1file_names=['Labelmaster Daily Sales by Product Group Part 1.xlsx','Labelmaster Daily Sales by Product Group Part 2.xlsx',            'Labelmaster Daily Sales by Product Group Part 3.xlsx','Labelmaster Daily Sales by Product Group Part 4.xlsx',            'Labelmaster Daily Sales by Product Group Part 5.xlsx','Labelmaster Daily Sales by Product Group Part 6.xlsx',            'Labelmaster Daily Sales by Product Group Part 7.xlsx','Labelmaster Daily Sales by Product Group Part 8.xlsx',            'Labelmaster Daily Sales by Product Group Part 9.xlsx']file_path='/Users/amanprasad/Documents/Courses_IIT_Fall_2019/Practicum/LabelMaster/IIT-UIC_Forecasting_Project_Work/Labelmaster Daily Sales/'df=read_excel_file(file_path,file_names)# reset_indexdf.reset_index(drop=True,inplace=True)#--------------------------------------------------------------------------------------------------------------------------Labelmaster_Daily_Sales=copy.deepcopy(df)# change datatypeLabelmaster_Daily_Sales['Department_Dim']=Labelmaster_Daily_Sales['Department_Dim'].astype('category')Labelmaster_Daily_Sales['Product_Group_Code']=Labelmaster_Daily_Sales['Product_Group_Code'].astype('category')Labelmaster_Daily_Sales['Sum_of_Sales']=Labelmaster_Daily_Sales['Sum_of_Sales'].astype('float')# YYYY-MM-DDLabelmaster_Daily_Sales['Posting_Date']= pd.to_datetime(Labelmaster_Daily_Sales['Posting_Date'],format='%Y-%m-%d')# check datatypes of columnscols=Labelmaster_Daily_Sales.columns#for i in range(len(cols)):#    print('{i}  {n}      {d}'.format (i=i,n=cols[i], d=Labelmaster_Daily_Sales.dtypes[cols[i]]))# sort value based on date columnLabelmaster_Daily_Sales.sort_values(by=['Posting_Date'], inplace=True)Labelmaster_Daily_Sales.reset_index(drop=True,inplace=True)# deleting rows whwre departs are 502,515,519def del_depart(ignore_depart, dataframe):    ignore_depart_index= list(dataframe[(dataframe['Department_Dim']==str(ignore_depart[0])) |                                       (dataframe['Department_Dim']==str(ignore_depart[1])) |                                      (dataframe['Department_Dim']==str(ignore_depart[2]))                                      ].index)        dataframe.drop((ignore_depart_index), inplace=True)    return dataframe# ignore_depart=['502','515','519']ignore_depart=['502','515','519']Labelmaster_Daily_Sales=del_depart(ignore_depart, Labelmaster_Daily_Sales)# deleting Product_Group_Code columnLabelmaster_Daily_Sales=Labelmaster_Daily_Sales.drop(['Product_Group_Code'],axis=1)unique_dates=list(Labelmaster_Daily_Sales['Posting_Date'].unique())l1=Labelmaster_Daily_Sales[Labelmaster_Daily_Sales['Posting_Date']==unique_dates[0]]print('Aggregation in progress. This may take some time.')df_grp=(Labelmaster_Daily_Sales.groupby(['Posting_Date','Department_Dim'])['Sum_of_Sales'].sum())print('Aggregation completed.')df_grp_1=df_grp.to_frame()#type(df_grp_1)#df_grp_1.index[0][0]df_grp_1.reset_index(inplace=True)#df_grp_1[df_grp_1['Posting_Date']==unique_dates[0]]df_grp_2=copy.deepcopy(df_grp_1)#df_grp_2.reset_index(inplace=True)  df_grp_2.drop(list(df_grp_2[df_grp_2['Sum_of_Sales'].isnull()==True].index),axis=0,inplace=True)#df_grp_2=pd.pivot_table(df_grp_2,index="Posting_Date",columns="Department_Dim", values='Sum_of_Sales').reset_index()df_grp_2 = df_grp_2.pivot(index='Posting_Date',columns='Department_Dim',values='Sum_of_Sales')print (df_grp_2)df_grp_2.columns = df_grp_2.columns.add_categories(['Posting_Date'])df_grp_2.reset_index(inplace=True)df_grp_2.rename_axis(None, axis=1)# checking null values column wisedf_grp_2.isnull().sum()# add 513 to 505 and 509 to 510# to do this we make all nan 0df_grp_2=df_grp_2.fillna(0)df_grp_2['505']= df_grp_2['505'] + df_grp_2['513']df_grp_2['510']= df_grp_2['510'] + df_grp_2['509']df_grp_2=df_grp_2.drop(['513'],axis=1)df_grp_2=df_grp_2.drop(['509'],axis=1)#-----------------------------------------------------------------------------------------# exporting df_grp_2 into csv#df_grp_2.to_csv(r'/Users/amanprasad/Documents/Courses_IIT_Fall_2019/Practicum/LabelMaster/IIT-UIC_Forecasting_Project_Work/Exported_file_Aman/formated_combined_sales.csv', index = False)#-----------------------------------------------------------------------------------------# aggregating daily into monthly sales data df_grp_3=copy.deepcopy(df_grp_2)# adding month and year to column categoriesdf_grp_3.columns = df_grp_3.columns.add_categories(['month'])df_grp_3['month']=df_grp_3['Posting_Date'].dt.monthdf_grp_3.columns = df_grp_3.columns.add_categories(['year'])df_grp_3['year']=df_grp_3['Posting_Date'].dt.yeardf_grp_3['month']=df_grp_3['year'].astype(str) + "-" + df_grp_3['month'].astype(str)# change Date's column datatypedf_grp_3['month']=pd.to_datetime((df_grp_3['month'].astype(str)),format='%Y-%m')# drop Posting Date columndf_grp_3.drop(['Posting_Date'],axis=1,inplace=True)df_grp_3.drop(['year'],axis=1,inplace=True)# aggregating sales of depart month wisedf_grp_3=(df_grp_3.groupby(['month'])[df_grp_3.columns].sum())# removing date from indexdf_grp_3.reset_index(inplace=True)# changing name of month column to Datedf_grp_3.rename(columns={"month": "Date"}, inplace=True)#-----------------------------------------------------------------------------------------# exporting df_grp_3 into csvdf_grp_3.to_csv(r'/Users/amanprasad/Documents/Courses_IIT_Fall_2019/Practicum/LabelMaster/IIT-UIC_Forecasting_Project_Work/Exported_file_Aman/formated_combined_monthly_sales.csv', index = False)